<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:media="http://search.yahoo.com/mrss/"><channel><title><![CDATA[Aba's Blog]]></title><description><![CDATA[Thoughts, stories and ideas.]]></description><link>http://localhost:2368/</link><image><url>http://localhost:2368/favicon.png</url><title>Aba&apos;s Blog</title><link>http://localhost:2368/</link></image><generator>Ghost 4.22</generator><lastBuildDate>Wed, 17 Nov 2021 16:54:43 GMT</lastBuildDate><atom:link href="http://localhost:2368/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[Vision-Based Adaptive Traffic Control on PSoC (ARM+FPGA) [2019]]]></title><description><![CDATA[<figure class="kg-card kg-image-card"><img src="https://lh4.googleusercontent.com/HJFQ4EJ9lUMKTIT-Y4n62H4m9ycX8UFHR6fZ1zfh3unr5-cxbKu583e375MhoGww3Z-DFubOuXnmxZtUZ2rlFDAS0PKhuIpH8RancFtczEgnTSvNr87KDv2PM-n0aFxx8XpWQyY6" class="kg-image" alt loading="lazy"></figure><figure class="kg-card kg-image-card"><img src="http://localhost:2368/content/images/2021/11/Slide19.JPG" class="kg-image" alt loading="lazy" width="960" height="720" srcset="http://localhost:2368/content/images/size/w600/2021/11/Slide19.JPG 600w, http://localhost:2368/content/images/2021/11/Slide19.JPG 960w" sizes="(min-width: 720px) 720px"></figure><figure class="kg-card kg-embed-card"><iframe width="200" height="150" src="https://www.youtube.com/embed/TXb7dYBRh3A?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></figure><h2 id="abstract">Abstract</h2><p>This system is to be installed at an intersection that captures image feeds of vehicles, accelerates vehicle detection using a custom coprocessor implemented on the FPGA fabric of a programmable system on chip (PSoC), measures traffic parameters and hence adaptively controls traffic signals at an intersection. The system further</p>]]></description><link>http://localhost:2368/vision-based-adaptive/</link><guid isPermaLink="false">61949a5547053101a188c58f</guid><dc:creator><![CDATA[Abarajithan Gnaneswaran]]></dc:creator><pubDate>Wed, 17 Nov 2021 15:55:04 GMT</pubDate><content:encoded><![CDATA[<figure class="kg-card kg-image-card"><img src="https://lh4.googleusercontent.com/HJFQ4EJ9lUMKTIT-Y4n62H4m9ycX8UFHR6fZ1zfh3unr5-cxbKu583e375MhoGww3Z-DFubOuXnmxZtUZ2rlFDAS0PKhuIpH8RancFtczEgnTSvNr87KDv2PM-n0aFxx8XpWQyY6" class="kg-image" alt loading="lazy"></figure><figure class="kg-card kg-image-card"><img src="http://localhost:2368/content/images/2021/11/Slide19.JPG" class="kg-image" alt loading="lazy" width="960" height="720" srcset="http://localhost:2368/content/images/size/w600/2021/11/Slide19.JPG 600w, http://localhost:2368/content/images/2021/11/Slide19.JPG 960w" sizes="(min-width: 720px) 720px"></figure><figure class="kg-card kg-embed-card"><iframe width="200" height="150" src="https://www.youtube.com/embed/TXb7dYBRh3A?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></figure><h2 id="abstract">Abstract</h2><p>This system is to be installed at an intersection that captures image feeds of vehicles, accelerates vehicle detection using a custom coprocessor implemented on the FPGA fabric of a programmable system on chip (PSoC), measures traffic parameters and hence adaptively controls traffic signals at an intersection. The system further includes methods for detecting vehicles from a video feed, tracking vehicles, measuring weighted vehicle flow, and hence calculating signal timings. The system is able to measure traffic parameters such as flow, velocity, density, and queue length with camera calibration.</p><p>The algorithms for detecting vehicles, tracking vehicles, measuring weighted vehicle flow are demonstrated to generalize well with remarkable count accuracy of 100% in daytime, &#xA0;97.7% in rainy time and 90.6% in night time when placed in multiple intersections with challenging lighting conditions where the system was not trained. The method for calculating traffic signal timings from weighted vehicle flow measurement is demonstrated to be stable, allowing hundreds of more vehicles per hour through the intersection and reducing average waiting time of vehicles significantly compared to the static timing values used in the real world when evaluated on a real world intersection modelled with real world traffic flow data in VISSIM traffic simulation software.</p><h2 id="gold-awardnational-best-quality-software">Gold Award - National Best Quality Software</h2><p>Our project won Gold at NBQSA 2020 (National ICT Awards) organized by British Computer Society in Tertiary Student Category and has been nominated for APICTA (Asia Pacific) Awards to be held in Malaysia.&#x200B; &#x200B; A patent for our system is currently under review at NIPO and the system is being further developed with funding from World Bank via AHEAD into a product by a multidisciplinary team of engineers through the Enterprise (Business Linkage Cell) of the University of Moratuwa, together with RDA and SD&amp;CC.&#x200B;</p><h2 id="startup-web-based-traffic-analytics">Startup: Web-based traffic analytics</h2><figure class="kg-card kg-embed-card"><iframe width="200" height="113" src="https://www.youtube.com/embed/UdplbYJY7hE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></figure><h2 id="methodology">Methodology</h2><figure class="kg-card kg-image-card"><img src="http://localhost:2368/content/images/2021/11/Slide6.JPG" class="kg-image" alt loading="lazy" width="960" height="720" srcset="http://localhost:2368/content/images/size/w600/2021/11/Slide6.JPG 600w, http://localhost:2368/content/images/2021/11/Slide6.JPG 960w" sizes="(min-width: 720px) 720px"></figure><h3 id="1-machine-learning">1. Machine Learning</h3><h4 id="11-inference-framework-for-precision-experiments-aba">1.1 Inference Framework for Precision Experiments (Aba)</h4><p>I built a Keras-like object-oriented inference framework using the multidimensional operations of numpy. Layer types (Conv, Relu...etc) are implemented as subclasses of common Layer class. They can be chained to build a model, which can forward propagate an image through multiple datapaths.</p><p>Github gist: <a href="https://gist.github.com/abarajithan11/66711711f13a499583b5afa43bcb1cfa">gist.github.com/abarajithan11/66711711f13a499583b5afa43bcb1cfa</a></p><p></p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="http://localhost:2368/content/images/2021/11/image-1.png" class="kg-image" alt loading="lazy" width="1740" height="819" srcset="http://localhost:2368/content/images/size/w600/2021/11/image-1.png 600w, http://localhost:2368/content/images/size/w1000/2021/11/image-1.png 1000w, http://localhost:2368/content/images/size/w1600/2021/11/image-1.png 1600w, http://localhost:2368/content/images/2021/11/image-1.png 1740w" sizes="(min-width: 720px) 720px"><figcaption>Part of my code showing convolution via Einstein summation and custom requantization scheme</figcaption></figure><h3 id="12-data-collection-devices-rukshan-chinthana-annotation-tehara">1.2 Data Collection Devices (Rukshan, Chinthana) &amp; Annotation (Tehara)</h3><p>Built four remotely powered, wirelessly data-collection devices. Collected, annotate and augment traffic images to create a Sri Lankan traffic dataset (1500 images).</p><figure class="kg-card kg-image-card"><img src="http://localhost:2368/content/images/2021/11/data-coll.jpg" class="kg-image" alt loading="lazy" width="960" height="720" srcset="http://localhost:2368/content/images/size/w600/2021/11/data-coll.jpg 600w, http://localhost:2368/content/images/2021/11/data-coll.jpg 960w" sizes="(min-width: 720px) 720px"></figure><h3 id="13-cnn-architecture-training-tehara">1.3 CNN Architecture &amp; Training (Tehara)</h3><p>Optimized the architecture of YOLOv2 object detection neural network for hardware implementation. Trained YOLOv2 and TinyYOLO.</p><ul><li>Fused batch normalization into convolution by modifying the weights and biases accordingly.</li><li>Interchanged conv =&gt; leaky-relu =&gt; max-pool to conv =&gt; max-pool =&gt; leaky-relu to reduce power.</li><li>Changed the output layer from 80 classes to 5 classes, by reusing weights of appropriate classes.</li><li>Changed grid size from (13 x 13) to (12 x 8) and designed the sensing algorithm accordingly</li><li>Trained with custom Sri Lankan Traffic Dataset (threewheelers)</li></ul><figure class="kg-card kg-gallery-card kg-width-wide"><div class="kg-gallery-container"><div class="kg-gallery-row"><div class="kg-gallery-image"><img src="http://localhost:2368/content/images/2021/11/Slide7.JPG" width="960" height="720" loading="lazy" alt srcset="http://localhost:2368/content/images/size/w600/2021/11/Slide7.JPG 600w, http://localhost:2368/content/images/2021/11/Slide7.JPG 960w" sizes="(min-width: 720px) 720px"></div><div class="kg-gallery-image"><img src="http://localhost:2368/content/images/2021/11/Slide8.JPG" width="960" height="720" loading="lazy" alt srcset="http://localhost:2368/content/images/size/w600/2021/11/Slide8.JPG 600w, http://localhost:2368/content/images/2021/11/Slide8.JPG 960w" sizes="(min-width: 720px) 720px"></div></div><div class="kg-gallery-row"><div class="kg-gallery-image"><img src="http://localhost:2368/content/images/2021/11/Slide9.JPG" width="960" height="720" loading="lazy" alt srcset="http://localhost:2368/content/images/size/w600/2021/11/Slide9.JPG 600w, http://localhost:2368/content/images/2021/11/Slide9.JPG 960w" sizes="(min-width: 720px) 720px"></div><div class="kg-gallery-image"><img src="http://localhost:2368/content/images/2021/11/Slide10.JPG" width="960" height="720" loading="lazy" alt srcset="http://localhost:2368/content/images/size/w600/2021/11/Slide10.JPG 600w, http://localhost:2368/content/images/2021/11/Slide10.JPG 960w" sizes="(min-width: 720px) 720px"></div></div></div></figure><h3 id="2-cnn-accelerator-design-aba">2. CNN Accelerator Design (Aba)</h3><p>Accelerator core v1.0 was designed to perform 12 of 3x3 convolutions in 9 clock cycles, using 9-muxes = 24, 3-muxes = 48, 16-bit registers = 144, &#xA0;Multipliers = 3, Accumulators = 3. This was redesigned into core 2.0, which was 4 times faster, using five times fewer 3-muxes, zero 9-muxes, about 20 times fewer registers (for the same speed), with 100% utilization of all multipliers and adders.</p><p>For 3x3, 1x1 layers of YOLOv2. Implemented at 50 MHz on Xilinx Z706.</p><figure class="kg-card kg-gallery-card kg-width-wide kg-card-hascaption"><div class="kg-gallery-container"><div class="kg-gallery-row"><div class="kg-gallery-image"><img src="http://localhost:2368/content/images/2021/11/Figure-7---system_diagram.png" width="751" height="633" loading="lazy" alt srcset="http://localhost:2368/content/images/size/w600/2021/11/Figure-7---system_diagram.png 600w, http://localhost:2368/content/images/2021/11/Figure-7---system_diagram.png 751w" sizes="(min-width: 720px) 720px"></div><div class="kg-gallery-image"><img src="http://localhost:2368/content/images/2021/11/Figure-8---conv_unit.png" width="692" height="472" loading="lazy" alt srcset="http://localhost:2368/content/images/size/w600/2021/11/Figure-8---conv_unit.png 600w, http://localhost:2368/content/images/2021/11/Figure-8---conv_unit.png 692w"></div></div></div><figcaption>System Design on ZYNQ Programmable SoC (left); One of the 192 cores, able to do 3x3 and 1x1 convolutions (right)</figcaption></figure><h3 id="3-tracking-algorithm-aba">3. Tracking Algorithm (Aba)</h3><p>Lightweight, IOU-based, standalone (no libraries) object tracking algorithm, robust to broken tracks, double counting...etc. Implemented in C (bare-metal on ARM side of ZYNQ FPGA.</p><ul><li>Built a custom lightweight tracking algorithm that can be implemented in C, without any libraries, so it can be run bare-metal (standalone) on the ZYNQ-PS side with minimal memory bandwidth (such that the ZYNQ-PL can use maximum bandwidth)</li><li>Near 97% vehicle counting accuracy in the daytime, 85% accuracy in the night, rainy time, on test data (on a road the CNN has never seen before)</li><li>Object detector (YOLOv2) has less accuracy. But tracking algorithm is designed to obtain &#xA0;near 100% accuracy in vehicle counting and identification</li></ul><figure class="kg-card kg-image-card"><img src="https://lh3.googleusercontent.com/mq9pvVp_5mRubWaCg8sdn_rPp077OCmNyZpXaNxfjvVKIUcMeK6ikCKxhE0TFhUCZ0foavMUUR2pk3VfkbnAKQvWubmHcg53bMYh031WxUN6qbT8iLgNyY-QOb-RYs2TYcFA_sXC" class="kg-image" alt loading="lazy"></figure><h3 id="4-delta-algorithm-for-traffic-timing-aba-vissim-verification-chinthana">4. Delta Algorithm for Traffic timing (Aba), VISSIM verification (Chinthana)</h3><p>Designed and tested 8 algorithms based on density, bounding box count, flow...etc. Finally built the Delta Algorithm. Works on top of static timing. Sensitivity is adjustable. During poor visibility, naturally falls back to static timing</p><figure class="kg-card kg-image-card"><img src="http://localhost:2368/content/images/2021/11/fyp_viva_final.jpg" class="kg-image" alt loading="lazy" width="960" height="720" srcset="http://localhost:2368/content/images/size/w600/2021/11/fyp_viva_final.jpg 600w, http://localhost:2368/content/images/2021/11/fyp_viva_final.jpg 960w" sizes="(min-width: 720px) 720px"></figure><figure class="kg-card kg-embed-card"><iframe width="200" height="150" src="https://www.youtube.com/embed/0_rzJ_J0B_4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></figure><h2 id="acknowledgement">Acknowledgement</h2><p>We are forever indebted to our families of Tehara and Chinthana for hosting our team for weeks/months during strikes and study breaks, allowing us to work together. In addition, we thank our Supervisors: Prof. Rohan and Prof. Saman Bandara for their support and assistance.</p>]]></content:encoded></item></channel></rss>