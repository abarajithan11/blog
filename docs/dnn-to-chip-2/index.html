<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <title>Neural Chip Design [2/4: Golden Model]</title>
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <link rel="preload" href="../assets/css/app.css%3Fv=b8c8d4f5ca.css" as="style" />
    <link rel="preload" href="../assets/js/manifest.js%3Fv=b8c8d4f5ca" as="script" />
    <link rel="preload" href="../assets/js/vendor/content-api.min.js%3Fv=b8c8d4f5ca" as="script" />
    <link rel="preload" href="../assets/js/vendor.js%3Fv=b8c8d4f5ca" as="script" />
    <link rel="preload" href="../assets/js/app.js%3Fv=b8c8d4f5ca" as="script" />
    <link rel="preconnect" href="https://polyfill.io">
    <link rel="dns-prefetch" href="https://polyfill.io">

      <link rel="preload" href="../assets/css/post.css%3Fv=b8c8d4f5ca.css" as="style" />
  <link rel="preload" href="../assets/js/post.js%3Fv=b8c8d4f5ca" as="script" />


    <style>
      /* These font-faces are here to make fonts work if the Ghost instance is installed in a subdirectory */

      /* source-sans-pro-regular */
      @font-face {
        font-family: 'Source Sans Pro';
        font-style: normal;
        font-weight: 400;
        font-display: swap;
        src: local('SourceSansPro-Regular'),
            url("../assets/fonts/source-sans-pro/latin/source-sans-pro-regular.woff2%3Fv=b8c8d4f5ca") format('woff2'),
            url("../assets/fonts/source-sans-pro/latin/source-sans-pro-regular.woff%3Fv=b8c8d4f5ca") format('woff');
      }

      /* source-sans-pro-600 */
      @font-face {
        font-family: 'Source Sans Pro';
        font-style: normal;
        font-weight: 600;
        font-display: swap;
        src: local('SourceSansPro-SemiBold'),
            url("../assets/fonts/source-sans-pro/latin/source-sans-pro-600.woff2%3Fv=b8c8d4f5ca") format('woff2'),
            url("../assets/fonts/source-sans-pro/latin/source-sans-pro-600.woff%3Fv=b8c8d4f5ca") format('woff');
      }

      /* source-sans-pro-700 */
      @font-face {
        font-family: 'Source Sans Pro';
        font-style: normal;
        font-weight: 700;
        font-display: swap;
        src: local('SourceSansPro-Bold'),
            url("../assets/fonts/source-sans-pro/latin/source-sans-pro-700.woff2%3Fv=b8c8d4f5ca") format('woff2'),
            url("../assets/fonts/source-sans-pro/latin/source-sans-pro-700.woff%3Fv=b8c8d4f5ca") format('woff');
      }

      /* iconmoon */
      @font-face {
        font-family: 'icomoon';
        font-weight: normal;
        font-style: normal;
        font-display: swap;
        src: url("../assets/fonts/icomoon/icomoon.eot%3F101fc3%3Fv=b8c8d4f5ca");
        src: url("../assets/fonts/icomoon/icomoon.eot%3F101fc3") format('embedded-opentype'),
        url("../assets/fonts/icomoon/icomoon.ttf%3F101fc3%3Fv=b8c8d4f5ca") format('truetype'),
        url("../assets/fonts/icomoon/icomoon.woff%3F101fc3%3Fv=b8c8d4f5ca") format('woff'),
        url("../assets/fonts/icomoon/icomoon.svg%3F101fc3") format('svg');
      }
    </style>

    <link rel="stylesheet" type="text/css" href="../assets/css/app.css%3Fv=b8c8d4f5ca.css" media="screen" />

      <link rel="stylesheet" type="text/css" href="../assets/css/post.css%3Fv=b8c8d4f5ca.css" media="screen" />


    

    <meta name="description" content="I wrote golden models in python to model the intended behavior of the chip. This outlines how I got pretrained models, extracted weights, applied my own quantization...etc." />
    <link rel="icon" href="../favicon.png" type="image/png" />
    <link rel="canonical" href="index.html" />
    <meta name="referrer" content="no-referrer-when-downgrade" />
    <link rel="amphtml" href="amp/index.html" />
    
    <meta property="og:site_name" content="Aba&#x27;s Blog" />
    <meta property="og:type" content="article" />
    <meta property="og:title" content="Neural Chip Design [2/4: Golden Model]" />
    <meta property="og:description" content="I wrote golden models in python to model the intended behavior of the chip. This outlines how I got pretrained models, extracted weights, applied my own quantization...etc." />
    <meta property="og:url" content="https://aba-blog.xyz/dnn-to-chip-2/" />
    <meta property="og:image" content="https://aba-blog.xyz/content/images/size/w2000/2022/01/b6f87d_cec29645262b492f95a30c10edec1090_mv2.jpg" />
    <meta property="article:published_time" content="2022-01-29T10:30:50.000Z" />
    <meta property="article:modified_time" content="2022-01-30T08:04:48.000Z" />
    <meta property="article:tag" content="Technical Projects" />
    
    <meta property="article:publisher" content="https://www.facebook.com/abarajithan11" />
    <meta property="article:author" content="https://www.facebook.com/abarajithan11" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Neural Chip Design [2/4: Golden Model]" />
    <meta name="twitter:description" content="I wrote golden models in python to model the intended behavior of the chip. This outlines how I got pretrained models, extracted weights, applied my own quantization...etc." />
    <meta name="twitter:url" content="https://aba-blog.xyz/dnn-to-chip-2/" />
    <meta name="twitter:image" content="https://aba-blog.xyz/content/images/size/w2000/2022/01/b6f87d_cec29645262b492f95a30c10edec1090_mv2.jpg" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="Abarajithan G" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="Technical Projects" />
    <meta property="og:image:width" content="2000" />
    <meta property="og:image:height" content="1366" />
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "Aba&#x27;s Blog",
        "url": "https://aba-blog.xyz/",
        "logo": {
            "@type": "ImageObject",
            "url": "https://aba-blog.xyz/favicon.png",
            "width": 60,
            "height": 60
        }
    },
    "author": {
        "@type": "Person",
        "name": "Abarajithan G",
        "image": {
            "@type": "ImageObject",
            "url": "https://aba-blog.xyz/content/images/2021/11/im_large_vignette.jpg",
            "width": 1600,
            "height": 1600
        },
        "url": "https://aba-blog.xyz/author/aba/",
        "sameAs": [
            "https://www.linkedin.com/in/abarajithan11",
            "https://www.facebook.com/abarajithan11"
        ]
    },
    "headline": "Neural Chip Design [2/4: Golden Model]",
    "url": "https://aba-blog.xyz/dnn-to-chip-2/",
    "datePublished": "2022-01-29T10:30:50.000Z",
    "dateModified": "2022-01-30T08:04:48.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "https://aba-blog.xyz/content/images/2022/01/b6f87d_cec29645262b492f95a30c10edec1090_mv2.jpg",
        "width": 2000,
        "height": 1366
    },
    "keywords": "Technical Projects",
    "description": "I wrote golden models in python to model the intended behavior of the chip. This outlines how I got pretrained models, extracted weights, applied my own quantization...etc.",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://aba-blog.xyz/"
    }
}
    </script>

    <meta name="generator" content="Ghost 4.32" />
    <link rel="alternate" type="application/rss+xml" title="Aba&#x27;s Blog" href="../rss/index.html" />
    <script defer src="https://unpkg.com/@tryghost/portal@~1.13.0/umd/portal.min.js" data-ghost="https://aba-blog.xyz/" crossorigin="anonymous"></script><style id="gh-members-styles">.gh-post-upgrade-cta-content,
.gh-post-upgrade-cta {
    display: flex;
    flex-direction: column;
    align-items: center;
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
    text-align: center;
    width: 100%;
    color: #ffffff;
    font-size: 16px;
}

.gh-post-upgrade-cta-content {
    border-radius: 8px;
    padding: 40px 4vw;
}

.gh-post-upgrade-cta h2 {
    color: #ffffff;
    font-size: 28px;
    letter-spacing: -0.2px;
    margin: 0;
    padding: 0;
}

.gh-post-upgrade-cta p {
    margin: 20px 0 0;
    padding: 0;
}

.gh-post-upgrade-cta small {
    font-size: 16px;
    letter-spacing: -0.2px;
}

.gh-post-upgrade-cta a {
    color: #ffffff;
    cursor: pointer;
    font-weight: 500;
    box-shadow: none;
    text-decoration: underline;
}

.gh-post-upgrade-cta a:hover {
    color: #ffffff;
    opacity: 0.8;
    box-shadow: none;
    text-decoration: underline;
}

.gh-post-upgrade-cta a.gh-btn {
    display: block;
    background: #ffffff;
    text-decoration: none;
    margin: 28px 0 0;
    padding: 8px 18px;
    border-radius: 4px;
    font-size: 16px;
    font-weight: 600;
}

.gh-post-upgrade-cta a.gh-btn:hover {
    opacity: 0.92;
}</style>
    <script defer src="../public/cards.min.js%3Fv=b8c8d4f5ca"></script>
    <link rel="stylesheet" type="text/css" href="../public/cards.min.css%3Fv=b8c8d4f5ca.css">
    <meta property="fb:admins" content="abarajithan11"/>
<style>
.post-template {
    text-align: justify;
}
</style>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/katex.css" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/katex.js" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.1/dist/contrib/auto-render.min.js" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
<script>
  const ghostSearchApiKey = 'f615b479aa70555d4c87186458'
</script>


<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/toolbar/prism-toolbar.min.css" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism-themes/1.9.0/prism-coldark-dark.min.css" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/line-numbers/prism-line-numbers.min.css" />
<style>
    pre[class*=language-] {
        margin: 0.5em 0;
        font-size: 0.8rem;
        background: #111;
    }
</style><style>:root {--ghost-accent-color: #2861bd;}</style>

    <style>
      :root {
        --primary-subtle-color: var(--ghost-accent-color) !important;
      }
    </style>

    <script>
      // @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&dn=expat.txt Expat
      const ghostHost = "https://aba-blog.xyz"
      // @license-end
    </script>

  </head>
  <body class="post-template tag-tech-projects">
    



  
<header class="m-header with-picture js-header">
  <div class="m-mobile-topbar" data-aos="fade-down">
    <button class="m-icon-button in-mobile-topbar js-open-menu" aria-label="Open menu">
      <span class="icon-menu" aria-hidden="true"></span>
    </button>
      <a href="../index.html" class="m-site-name in-mobile-topbar">
        Aba&#x27;s Blog
      </a>
    <button class="m-icon-button in-mobile-topbar js-open-search" aria-label="Open search">
      <span class="icon-search" aria-hidden="true"></span>
    </button>
  </div>

  <div class="m-menu js-menu">
    <button class="m-icon-button outlined as-close-menu js-close-menu" aria-label="Close menu">
      <span class="icon-close"></span>
    </button>
    <div class="m-menu__main" data-aos="fade-down">
      <div class="l-wrapper">
        <div class="m-nav js-main-nav">
          <nav class="m-nav__left js-main-nav-left" role="navigation" aria-label="Main menu">
            <ul>
                <li class="only-desktop">
                  <a href="../index.html" class="m-site-name in-desktop-menu">
                    Aba&#x27;s Blog
                  </a>
                </li>
                
    <li class="nav-cv">
      <a href="https://aba-blog.xyz/cv.pdf">CV</a>
    </li>
    <li class="nav-tech-projects">
      <a href="../tag/tech-projects/index.html">Tech Projects</a>
    </li>
    <li class="nav-travels">
      <a href="../tag/travels/index.html">Travels</a>
    </li>
    <li class="nav-thoughts">
      <a href="../tag/thoughts/index.html">Thoughts</a>
    </li>
    <li class="nav-stories">
      <a href="../tag/stories/index.html">Stories</a>
    </li>
    <li class="nav-reviews">
      <a href="../tag/reviews/index.html">Reviews</a>
    </li>
    <li class="nav-teaching">
      <a href="../tag/teaching/index.html">Teaching</a>
    </li>
    <li class="nav-community-work">
      <a href="../tag/community-work/index.html">Community Work</a>
    </li>

              <li class="submenu-option js-submenu-option">
                <button class="m-icon-button in-menu-main more js-toggle-submenu" aria-label="Open submenu">
                  <span class="icon-more" aria-hidden="true"></span>
                </button>
                <div class="m-submenu js-submenu">
                  <div class="l-wrapper in-submenu">
                    <section class="m-recent-articles">
                      <h3 class="m-submenu-title in-recent-articles">Recent articles</h3>
                          <div class="glide js-recent-slider">
                            <div class="glide__track" data-glide-el="track">
                              <div class="glide__slides">
                                <div class="glide__slide">
                                  <a href="../dnn-to-chip-4/index.html" class="m-recent-article">
                                    <div class="m-recent-article__picture ">
                                        <img src="../content/images/size/w300/2022/01/sys-4.jpg" loading="lazy" alt="">
                                    </div>
                                    <h3 class="m-recent-article__title js-recent-article-title" title="Neural Chip Design [4/4: SoC Integration &amp; Firmware]">
                                      Neural Chip Design [4/4: SoC Integration &amp; Firmware]
                                    </h3>
                                    <span class="m-recent-article__date">a month ago</span>
                                  </a>
                                </div>
                                <div class="glide__slide">
                                  <a href="../dnn-to-chip-3/index.html" class="m-recent-article">
                                    <div class="m-recent-article__picture ">
                                        <img src="../content/images/size/w300/2022/01/vlcsnap-2022-01-30-00h01m19s402.png" loading="lazy" alt="">
                                    </div>
                                    <h3 class="m-recent-article__title js-recent-article-title" title="Neural Chip Design [3/4: RTL Design &amp; Verification]">
                                      Neural Chip Design [3/4: RTL Design &amp; Verification]
                                    </h3>
                                    <span class="m-recent-article__date">a month ago</span>
                                  </a>
                                </div>
                                <div class="glide__slide">
                                  <a href="index.html" class="m-recent-article">
                                    <div class="m-recent-article__picture ">
                                        <img src="../content/images/size/w300/2022/01/b6f87d_cec29645262b492f95a30c10edec1090_mv2.jpg" loading="lazy" alt="">
                                    </div>
                                    <h3 class="m-recent-article__title js-recent-article-title" title="Neural Chip Design [2/4: Golden Model]">
                                      Neural Chip Design [2/4: Golden Model]
                                    </h3>
                                    <span class="m-recent-article__date">a month ago</span>
                                  </a>
                                </div>
                                <div class="glide__slide">
                                  <a href="../dnn-to-chip-1/index.html" class="m-recent-article">
                                    <div class="m-recent-article__picture ">
                                        <img src="../content/images/size/w300/2022/01/cov-14.jpg" loading="lazy" alt="">
                                    </div>
                                    <h3 class="m-recent-article__title js-recent-article-title" title="Neural Chip Design [1/4: Overview]">
                                      Neural Chip Design [1/4: Overview]
                                    </h3>
                                    <span class="m-recent-article__date">a month ago</span>
                                  </a>
                                </div>
                              </div>
                            </div>
                          </div>
                    </section>
                    <section class="m-tags">
                      <h3 class="m-submenu-title">Tags</h3>
                        <ul>
                            <li>
                              <a href="../tag/australia/index.html">Australia</a>
                            </li>
                            <li>
                              <a href="../tag/community-work/index.html">Community Work</a>
                            </li>
                            <li>
                              <a href="../tag/india/index.html">India</a>
                            </li>
                            <li>
                              <a href="../tag/nature/index.html">Nature</a>
                            </li>
                            <li>
                              <a href="../tag/reviews/index.html">Reviews</a>
                            </li>
                            <li>
                              <a href="../tag/stories/index.html">Stories</a>
                            </li>
                            <li>
                              <a href="../tag/teaching/index.html">Teaching</a>
                            </li>
                            <li>
                              <a href="../tag/tech-projects/index.html">Technical Projects</a>
                            </li>
                            <li>
                              <a href="../tag/thoughts/index.html">Thoughts</a>
                            </li>
                            <li>
                              <a href="../tag/travels/index.html">Travels</a>
                            </li>
                        </ul>
                    </section>
                  </div>
                </div>
              </li>
            </ul>
          </nav>
          <div class="m-nav__right">
            <button class="m-icon-button in-menu-main js-open-search" aria-label="Open search">
              <span class="icon-search" aria-hidden="true"></span>
            </button>
            <div class="m-toggle-darkmode js-tooltip" data-tippy-content="Toggle light/dark mode" tabindex="0">
              <label for="toggle-darkmode" class="sr-only">
                Toggle light/dark mode
              </label>
              <input id="toggle-darkmode" type="checkbox" class="js-toggle-darkmode">
              <div>
                <span class="icon-moon moon" aria-hidden="true"></span>
                <span class="icon-sunny sun" aria-hidden="true"></span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

</header>

<main class="main-wrap">
    
  <section class="m-hero with-picture" data-aos="fade">
    <div class="m-hero__picture in-post">
      <img srcset="../content/images/size/w300/2022/01/b6f87d_cec29645262b492f95a30c10edec1090_mv2.jpg 300w, ../content/images/size/w600/2022/01/b6f87d_cec29645262b492f95a30c10edec1090_mv2.jpg 600w, ../content/images/size/w1000/2022/01/b6f87d_cec29645262b492f95a30c10edec1090_mv2.jpg 1000w, ../content/images/size/w2000/2022/01/b6f87d_cec29645262b492f95a30c10edec1090_mv2.jpg 2000w" sizes="(max-width: 600px) 600px, (max-width: 1000px) 1000px, 2000px" src="../content/images/size/w2000/2022/01/b6f87d_cec29645262b492f95a30c10edec1090_mv2.jpg" alt="" />
    </div>
    </section>
  
  <article>
    <div class="l-content in-post">
        <div class="l-wrapper in-post  js-aos-wrapper" data-aos="fade-up"
          data-aos-delay="300">
          <div
            class="l-post-content js-progress-content">
            <header class="m-heading">
              <h1 class="m-heading__title in-post">Neural Chip Design [2/4: Golden Model]</h1>
              <div class="m-heading__meta">
                  <a href="../tag/tech-projects/index.html" class="m-heading__meta__tag">Technical Projects</a>
                  <span class="m-heading__meta__divider" aria-hidden="true">&bull;</span>
                <span class="m-heading__meta__time">Jan 29, 2022</span>
              </div>
            </header>
            <div class="pos-relative js-post-content">
              <div class="m-share">
                <div class="m-share__content js-sticky">
                  <a href="https://www.facebook.com/sharer/sharer.php?u=https://aba-blog.xyz/dnn-to-chip-2/"
                    class="m-icon-button filled in-share" target="_blank" rel="noopener" aria-label="Facebook">
                    <span class="icon-facebook" aria-hidden="true"></span>
                  </a>
                  <a href="https://twitter.com/intent/tweet?text=Neural%20Chip%20Design%20%5B2%2F4%3A%20Golden%20Model%5D&url=https://aba-blog.xyz/dnn-to-chip-2/"
                    class="m-icon-button filled in-share" target="_blank" rel="noopener" aria-label="Twitter">
                    <span class="icon-twitter" aria-hidden="true"></span>
                  </a>
                  <a href="https://www.linkedin.com/sharing/share-offsite/?url=https://aba-blog.xyz/dnn-to-chip-2/"
                    class="m-icon-button filled in-share" target="_blank" rel="noopener" aria-label="LinkedIn">
                    <span class="icon-linkedin" aria-hidden="true"></span>
                  </a>
                  <a href="https://reddit.com/submit?url=https://aba-blog.xyz/dnn-to-chip-2/&title=Neural%20Chip%20Design%20%5B2%2F4%3A%20Golden%20Model%5D"
                    class="m-icon-button filled in-share" target="_blank" rel="noopener" aria-label="Reddit">
                    <span class="icon-reddit" aria-hidden="true"></span>
                  </a>
                  <button class="m-icon-button filled in-share progress js-scrolltop" aria-label="Scroll to top">
                    <span class="icon-arrow-top" aria-hidden="true"></span>
                    <svg aria-hidden="true">
                      <circle class="progress-ring__circle js-progress" fill="transparent" r="0" />
                    </svg>
                  </button>
                </div>
              </div>
              <p></p><blockquote>This is a series of articles <a href="https://aba-blog.xyz/dnn-to-chip-1/index.html">[overview]</a> outlining the  workflow of 15 steps, which I developed over the past few years through building my own DNN accelerator: Kraken<a href="https://arxiv.org/abs/2112.02793"> [arXiv paper]</a>.</blockquote><p>Golden Models are essential to hardware (FPGA/ASIC) development. They model the expected behavior of a chip using a high-level language, such that they can be built relatively fast, with almost zero chance of error. The input and expected output test vectors for every RTL module are generated using them, and the simulation output from the testbench is compared against their 'gold standard.'</p><p>I first obtain pretrained DNNs from PyTorch / Tensorflow model zoo, analyze them, then load them into the custom DNN inference framework I have built with NumPy stack to ensure I fully understand each operation. I then generate test vectors from those golden models.</p><h2 id="steps">Steps:</h2><!--kg-card-begin: markdown--><ol>
<li><strong>PyTorch/TensorFlow</strong>: Explore DNN models, quantize &amp; extract weights</li>
<li><strong>Golden Model in Python (NumPy stack)</strong>: Custom OOP framework, process the weights, convert to custom datatypes</li>
</ol>
<!--kg-card-end: markdown--><div class="kg-card kg-header-card kg-width-full kg-size-small kg-style-dark" style="" data-kg-background-image=""><h2 class="kg-header-card-header">1. Tensorflow / PyTorch</h2></div><p>Tensorflow (Google) and PyTorch (Facebook) are the two competing open source libraries used to build, train, quantize and deploy modern deep neural networks. </p><p>Both frameworks provide high-level, user-friendly classes and functions such as Conv2D, model.fit() to build &amp; train networks. Each such high-level API is implemented using their own low-level tensor operations (matmul, einsum), which also can be used by the users. Those operations are implemented using their C++ backend, accelerated by high performant libraries like eigen and CUDA. Once we define the models using Python, the C++ code underneath pulls the load, making them fast as well as user-friendly.</p><h3 id="11-download-explore-pretrained-dnn-models">1.1. Download &amp; Explore Pretrained DNN Models</h3><p>As the first step, I obtained the pretrained models from either <a href="https://keras.io/api/applications/">Keras.Applications</a> or <a href="https://pytorch.org/serve/model_zoo.html">PyTorch Model Zoo</a>.</p><figure class="kg-card kg-code-card"><pre><code class="language-python">import tensorflow as tf
from tensorflow.keras.applications import VGG16

vgg16 = VGG16(
    include_top=True,
    weights="imagenet",
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation="softmax",
)

vgg16.save('saved_model/vgg16')
vgg16.summary()</code></pre><figcaption>Get VGG16 from TensorFlow zoo (Keras.Applications)</figcaption></figure><figure class="kg-card kg-code-card"><pre><code class="language-python">import torch
model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)
model.eval()
torch.save(model, "alexnet.pt")</code></pre><figcaption>Get AlexNet from PyTorch Model Zoo</figcaption></figure><h3 id="12-build-models-retrain-if-needed-pytorch">1.2. <strong>Build Models &amp; </strong>Retrain if needed (PyTorch)</h3><p>PyTorch is more intuitive, pythonic and bliss to work with. I use it to build new models and train them if needed. </p><figure class="kg-card kg-code-card"><pre><code class="language-python">import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets
from torchvision import transforms as T
from torch.optim.lr_scheduler import StepLR

H = 28
N = 32
device = torch.device("cuda")

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(H**2, 32)
        self.fc2 = nn.Linear(32, 10)
    def forward(self, x):
        x = self.fc1(x)
        x = F.leaky_relu(x,0.01)
        x = self.fc2(x)
        output = F.log_softmax(x, dim=1)
        return output
        
model = Net().to(device)</code></pre><figcaption>Building a simple fully connected network in PyTorch</figcaption></figure><figure class="kg-card kg-code-card"><pre><code class="language-python">''' Create Data Loaders to efficiently pull data '''
transform = T.Compose([T.ToTensor(), T.Lambda(lambda x: torch.flatten(x))])
dataset1  = datasets.MNIST('../data', train=True, download=True, transform=transform)
dataset2  = datasets.MNIST('../data', train=False, transform=transform)

train_loader = torch.utils.data.DataLoader(dataset1,batch_size=N)
test_loader = torch.utils.data.DataLoader(dataset2,batch_size=N)

''' Functions to Test &amp; Train '''

def train(model, device, train_loader, optimizer, epoch):
    model.train()
    for (data, target) in train_loader:
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = F.nll_loss(output, target)
        loss.backward()
        optimizer.step()
        print(f'Train, epoch: {epoch}, loss: {loss.item():.6f}')

def test(model, device, test_loader):
    model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += F.nll_loss(output, target, reduction='sum').item()
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()
    test_loss /= len(test_loader.dataset)
    print(f'Test, loss: {test_loss}, acc: {100*correct/len(test_loader.dataset):.0f}')

optimizer = optim.Adadelta(model.parameters(), lr=1.0)
scheduler = StepLR(optimizer, step_size=1, gamma=0.7)

''' Train for 50 Epochs '''
for epoch in range(1, 51):
    train(model, device, train_loader, optimizer, epoch)
    test(model, device, test_loader)
    scheduler.step()

''' Save Trained Model '''
torch.save(model, "mnist_cnn.pt")</code></pre><figcaption>Training the model in PyTorch with MNIST dataset</figcaption></figure><h3 id="13-convert-torch-models-to-tensorflow">1.3. Convert Torch Models to Tensorflow</h3><p>However, the support for int8 quantization for PyTorch is still experimental. Therefore, for most of my work, I use pretrained models from Tensorflow, whose quantization library (TFLite) is much superior. </p><p>Some models, like AlexNet, are not found in Keras.Applications. Therefore, I load them from PyTorch Model Zoo and convert them to ONNX (the common open-source format) and then load them in Tensorflow.</p><figure class="kg-card kg-code-card"><pre><code class="language-python">import torch
from PIL import Image
from torchvision import transforms

model = torch.load('alexnet.pt')

input_image = Image.open('dog.jpg')
preprocess = transforms.Compose([
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),
])
input_tensor = preprocess(input_image)
input_batch = input_tensor.unsqueeze(0)

torch.onnx.export(model, input_batch, "alexnet.onnx",
		input_names=['input'], output_names=['output'])</code></pre><figcaption>Open the saved AlexNet model and export as ONNX</figcaption></figure><figure class="kg-card kg-code-card"><pre><code class="language-python"># First install onnx2keras with: pip install onnx onnx2keras
import onnx
from onnx2keras import onnx_to_keras
onnx_model = onnx.load("alexnet.onnx")
k_model = onnx_to_keras(onnx_model, ['input'], change_ordering=True)
k_model.save('saved_model/alexnet')</code></pre><figcaption>Convert ONNX model to Keras (Tensorflow)</figcaption></figure><h3 id="14-quantize-models-with-tensorflowlite">1.4. Quantize Models with TensorFlowLite</h3><p>Following is an example of loading a float32 model (VGG16) from tensorflow's savedmodel format (1.1), testing it, quantizing it to int8, and testing  &amp; saving the quantized network.</p><pre><code class="language-python">import tensorflow as tf
filenames = glob("dataset/*.jpg")

'''
LOAD AND TEST FLOAT32 MODEL
'''
prep_fn = tf.keras.applications.vgg16.preprocess_input
model = tf.keras.models.load_model(f'saved_model/vgg16')
h = model.input_shape[1]

import cv2
from glob import glob
import numpy as np
def representative_data_gen():
    for im_path in filenames:
        im = cv2.imread(im_path)
        im = cv2.resize(im, (h,h))
        im = im[None,:,:,::-1]
        im = prep_fn(im)
        im = tf.convert_to_tensor(im)
        yield [im]

images = list(representative_data_gen())

predictions = np.zeros((len(images),), dtype=int)
for i, image in enumerate(images):
    output = model(image[0])[0]
    predictions[i] = output.numpy().argmax()
print(predictions)

'''
CONVERT AND SAVE INT8 MODEL (STATIC QUANTIZATION)
'''
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_data_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.int8
converter.inference_output_type = tf.int8
tflite_model_quant = converter.convert()

import pathlib
tflite_model_quant_file = pathlib.Path(f"tflite/vgg16.tflite")
tflite_model_quant_file.write_bytes(tflite_model_quant)

'''
LOAD AND TEST QUANTIZED MODEL
'''
interpreter = tf.lite.Interpreter(model_path=str(tflite_model_quant_file))
interpreter.allocate_tensors()
input_details = interpreter.get_input_details()[0]
output_details = interpreter.get_output_details()[0]

images = list(representative_data_gen())
predictions = np.zeros((len(images),), dtype=int)

for i, image in enumerate(images):
    image = image[0]
    input_scale, input_zero_point = input_details["quantization"]
    image = image / input_scale + input_zero_point

    test_image = image.numpy().astype(input_details["dtype"])
    interpreter.set_tensor(input_details["index"], test_image)
    interpreter.invoke()
    output = interpreter.get_tensor(output_details["index"])[0]
    predictions[i] = output.argmax()

print(predictions)</code></pre><h3 id="15-explore-model-architecture">1.5 Explore Model Architecture</h3><p><a href="https://netron.app/">Netron </a>is a great tool for opening tensorflow's 32-bit models (savedmodel), tflite's int8 models (tflite), pytorch models (pt), ONNX models, and more, to observe the architecture and tensor names.</p><figure class="kg-card kg-image-card"><img src="../content/images/2022/01/image-2.png" class="kg-image" alt loading="lazy" width="1062" height="1042" srcset="../content/images/size/w600/2022/01/image-2.png 600w, ../content/images/size/w1000/2022/01/image-2.png 1000w, ../content/images/2022/01/image-2.png 1062w" sizes="(min-width: 720px) 720px"></figure><div class="kg-card kg-header-card kg-width-full kg-size-small kg-style-dark" style="" data-kg-background-image=""><h2 class="kg-header-card-header">2. Golden Model</h2><h3 class="kg-header-card-subheader">Python (NumPy stack)</h3></div><p>After obtaining the pretrained model, I need to 100% understand what operations are involved and how they are applied as data flows through the network. The best way to do this is to re-do it myself from scratch and obtain exactly the same results. </p><h3 id="21-custom-quantization-scheme">2.1. Custom Quantization Scheme</h3><figure class="kg-card kg-image-card"><img src="../content/images/2022/01/quant2.jpg" class="kg-image" alt loading="lazy" width="1280" height="606" srcset="../content/images/size/w600/2022/01/quant2.jpg 600w, ../content/images/size/w1000/2022/01/quant2.jpg 1000w, ../content/images/2022/01/quant2.jpg 1280w" sizes="(min-width: 720px) 720px"></figure><h3 id="22-custom-inference-framework-oop-python">2.2. Custom Inference Framework (OOP, Python)</h3><p>For this, I built a custom framework in Python. It is structured like Keras with the following classes, inheriting as follows:</p><!--kg-card-begin: markdown--><ul>
<li>MyModel</li>
<li>MyLayer
<ul>
<li>MyConv</li>
<li>MyLeakyReLU</li>
<li>MyMaxpool</li>
<li>MyConcat</li>
<li>MySpaceToDepth</li>
<li>MyFlatten</li>
</ul>
</li>
</ul>
<!--kg-card-end: markdown--><p>A MyModel object has a list of objects from MyLayer's children's classes. It's constructor extracts weights from tflite and sets them to the layers. A set of images can flow through the layers through a recursive call to the last layer. Following is the stripped-down version of the MyConv implementation.</p><figure class="kg-card kg-code-card"><pre><code class="language-python">class MyConv(MyLayer):
    def __init__(self,
                 weights_biases,
                 prev_layer=None,
                 bn_weights=None,
                 name='',
                 np_dtype=np.float64,
                 np_dtype_sum=np.float64,
                 np_dtype_conv_out=np.float64,
                 float_dtype=np.float64,
                 bits_conv_out=32,
                 quantize=False,
                 float_ieee=True):

        MyLayer.__init__(self,
                         name=name,
                         prev_layer=prev_layer,
                         np_dtype=np_dtype,
                         quantize=quantize,
                         float_ieee=float_ieee)
        self.np_dtype_sum = np_dtype_sum
        self.np_dtype_conv_out = np_dtype_conv_out
        self.float_dtype = float_dtype

        assert len(weights_biases[0].shape) == 4
        self.weights = weights_biases[0].astype(self.np_dtype)
        self.weights_flipped = np.flip(
            self.weights, [0, 1]).astype(self.np_dtype)
        self.kernel = self.weights.shape[0:2]
        self.in_ch_n = self.weights.shape[2]
        self.out_ch_n = self.weights.shape[3]
        self.biases = weights_biases[1].astype(self.np_dtype)

        self.fuse_bn(bn_weights)

        if self.quantize:
            self.clip_max = 2**(bits_conv_out-1)-1
            self.clip_min = -2**(bits_conv_out-1)

    def np_out(self, in_data):
        if self.quantize:
            in_data = self.in_data.copy().astype(self.np_dtype_sum)
            weights = self.weights.copy().astype(self.np_dtype_sum)

            self.np_out_data = self.conv2d_einsum(in_data, weights)

            self.np_out_data = np.clip(self.np_out_data, self.clip_min, self.clip_max)
            self.np_out_data = self.np_out_data.astype(self.np_dtype_conv_out)
        else:
            out = self.conv2d_einsum(self.in_data, self.weights)
            out += self.biases
            self.np_out_data = self.decode(self.encode(out))
        return self.np_out_data

    def fuse_bn(self, bn_weights, epsilon=0.001):
        self.gamma, self.beta, self.mean, self.variance = bn_weights
        self.epsilon = epsilon

        scale = self.gamma / np.sqrt(self.variance + self.epsilon)

        self.pure_weights = self.weights.copy()
        self.pure_biases = self.biases.copy()

        self.weights = self.weights * scale
        self.weights_flipped = np.flip(self.weights, [0, 1])
        self.biases = beta + scale * (self.biases - self.mean)

    @staticmethod
    def conv2d_einsum(img, kernel):
        pad_h = kernel.shape[0]//2
        pad_w = kernel.shape[1]//2

        out_batch = []
        for n in range(img.shape[0]):
            padding = ((pad_h, pad_h), (pad_w, pad_w), (0, 0))
            img_pad = np.pad(img[n], padding, 'constant')

            sub_shape = tuple(np.subtract(img_pad.shape, kernel.shape[0:-1])+1)
            shape = kernel.shape[0:-1] + sub_shape
            strd = np.lib.stride_tricks.as_strided
            submatrices = strd(img_pad,shape,img_pad.strides*2,writeable=False)

            out_batch += [np.einsum('ijkl,ijkmno-&gt;mnl', kernel, submatrices)]
        return np.array(out_batch)</code></pre><figcaption>stripped-down version of the MyConv implementation</figcaption></figure><h3 id="23-rebuilding-the-model-debugging">2.3. Rebuilding the model &amp; Debugging</h3><p>I then rebuild the model using the above framework, pass data and tweak things until I get the exact same output. That tells me I have understood all the operations going on inside the model.</p><figure class="kg-card kg-gallery-card kg-width-wide"><div class="kg-gallery-container"><div class="kg-gallery-row"><div class="kg-gallery-image"><img src="../content/images/2022/01/image-3.png" width="723" height="862" loading="lazy" alt srcset="../content/images/size/w600/2022/01/image-3.png 600w, ../content/images/2022/01/image-3.png 723w" sizes="(min-width: 720px) 720px"></div><div class="kg-gallery-image"><img src="../content/images/2022/01/image-4.png" width="1331" height="655" loading="lazy" alt srcset="../content/images/size/w600/2022/01/image-4.png 600w, ../content/images/size/w1000/2022/01/image-4.png 1000w, ../content/images/2022/01/image-4.png 1331w" sizes="(min-width: 720px) 720px"></div><div class="kg-gallery-image"><img src="../content/images/2022/01/image-5.png" width="1269" height="869" loading="lazy" alt srcset="../content/images/size/w600/2022/01/image-5.png 600w, ../content/images/size/w1000/2022/01/image-5.png 1000w, ../content/images/2022/01/image-5.png 1269w" sizes="(min-width: 720px) 720px"></div></div></div></figure><p>Once I've understood the model inside-out, I start designing the hardware on the whiteboard.</p><h2 id="next">Next:</h2><figure class="kg-card kg-bookmark-card"><a class="kg-bookmark-container" href="https://aba-blog.xyz/dnn-to-chip-3/index.html"><div class="kg-bookmark-content"><div class="kg-bookmark-title">Neural Chip Design [3/4: Digital Design &amp; Verification]</div><div class="kg-bookmark-description">How I designed modules in the whiteboard, then wrote SystemVerilog RTL, built testbenches, prepared test vectors, and debugged them.</div><div class="kg-bookmark-metadata"><img class="kg-bookmark-icon" src="https://aba-blog.xyz/favicon.png" alt=""><span class="kg-bookmark-author">Aba&#x27;s Blog</span><span class="kg-bookmark-publisher">Abarajithan G</span></div></div><div class="kg-bookmark-thumbnail"><img src="https://aba-blog.xyz/content/images/size/w2000/2022/01/vlcsnap-2022-01-30-00h01m19s402.png" alt=""></div></a></figure>
                <section class="m-tags in-post">
                  <h3 class="m-submenu-title">Tags</h3>
                  <ul>
                      <li>
                        <a href="../tag/tech-projects/index.html" title="Technical Projects">Technical Projects</a>
                      </li>
                  </ul>
                </section>
            </div>
          </div>
        </div>

          <section class="m-comments">
            <div class="l-wrapper in-comments">
              <div class="fb-comments" data-href="https://aba-blog.xyz/dnn-to-chip-2/" data-width="100%" data-numposts="10" data-colorscheme="light" style="background-color: white"></div>
            </div>
          </section>


          <section class="m-recommended">
            <div class="l-wrapper in-recommended">
              <h3 class="m-section-title in-recommended">Recommended for you</h3>
              <div class="m-recommended-articles">
                <div class="m-recommended-slider glide js-recommended-slider">
                  <div class="glide__track" data-glide-el="track">
                    <div class="glide__slides">
                      
    <div class="m-recommended-slider__item glide__slide">
  <article class="m-article-card  post tag-tech-projects">
    <div class="m-article-card__picture">
      <a href="../dnn-to-chip-4/index.html" class="m-article-card__picture-link" aria-hidden="true" tabindex="-1"></a>
        <img class="m-article-card__picture-background" src="../content/images/size/w600/2022/01/sys-4.jpg" loading="lazy" alt="">
      <a href="../author/aba/index.html" class="m-article-card__author js-tooltip" aria-label="Abarajithan G" data-tippy-content="Posted by Abarajithan G ">
          <div style="background-image: url(../content/images/size/w100/2021/11/im_large_vignette.jpg);"></div>
      </a>
    </div>
      <div class="m-article-card__info">
        <a href="../tag/tech-projects/index.html" class="m-article-card__tag">Technical Projects</a>
      <a href="../dnn-to-chip-4/index.html" class="m-article-card__info-link" aria-label="Neural Chip Design [4/4: SoC Integration &amp; Firmware]">
        <div>
          <h2 class="m-article-card__title js-article-card-title " title="Neural Chip Design [4/4: SoC Integration &amp; Firmware]">
            Neural Chip Design [4/4: SoC Integration &amp; Firmware]
          </h2>
        </div>
        <div class="m-article-card__timestamp">
          <span>a month ago</span>
          <span>&bull;</span>
          <span>10 min read</span>
        </div>
      </a>
    </div>
  </article>
    </div>
    <div class="m-recommended-slider__item glide__slide">
  <article class="m-article-card  post tag-tech-projects">
    <div class="m-article-card__picture">
      <a href="../dnn-to-chip-3/index.html" class="m-article-card__picture-link" aria-hidden="true" tabindex="-1"></a>
        <img class="m-article-card__picture-background" src="../content/images/size/w600/2022/01/vlcsnap-2022-01-30-00h01m19s402.png" loading="lazy" alt="">
      <a href="../author/aba/index.html" class="m-article-card__author js-tooltip" aria-label="Abarajithan G" data-tippy-content="Posted by Abarajithan G ">
          <div style="background-image: url(../content/images/size/w100/2021/11/im_large_vignette.jpg);"></div>
      </a>
    </div>
      <div class="m-article-card__info">
        <a href="../tag/tech-projects/index.html" class="m-article-card__tag">Technical Projects</a>
      <a href="../dnn-to-chip-3/index.html" class="m-article-card__info-link" aria-label="Neural Chip Design [3/4: RTL Design &amp; Verification]">
        <div>
          <h2 class="m-article-card__title js-article-card-title " title="Neural Chip Design [3/4: RTL Design &amp; Verification]">
            Neural Chip Design [3/4: RTL Design &amp; Verification]
          </h2>
        </div>
        <div class="m-article-card__timestamp">
          <span>a month ago</span>
          <span>&bull;</span>
          <span>12 min read</span>
        </div>
      </a>
    </div>
  </article>
    </div>
    <div class="m-recommended-slider__item glide__slide">
  <article class="m-article-card  post tag-tech-projects featured">
    <div class="m-article-card__picture">
      <a href="../dnn-to-chip-1/index.html" class="m-article-card__picture-link" aria-hidden="true" tabindex="-1"></a>
        <img class="m-article-card__picture-background" src="../content/images/size/w600/2022/01/cov-14.jpg" loading="lazy" alt="">
      <a href="../author/aba/index.html" class="m-article-card__author js-tooltip" aria-label="Abarajithan G" data-tippy-content="Posted by Abarajithan G ">
          <div style="background-image: url(../content/images/size/w100/2021/11/im_large_vignette.jpg);"></div>
      </a>
        <a href="../dnn-to-chip-1/index.html" class="m-article-card__featured js-tooltip" data-tippy-content="Featured" aria-label="Featured">
          <span class="icon-star" aria-hidden="true"></span>
        </a>
    </div>
      <div class="m-article-card__info">
        <a href="../tag/tech-projects/index.html" class="m-article-card__tag">Technical Projects</a>
      <a href="../dnn-to-chip-1/index.html" class="m-article-card__info-link" aria-label="Neural Chip Design [1/4: Overview]">
        <div>
          <h2 class="m-article-card__title js-article-card-title " title="Neural Chip Design [1/4: Overview]">
            Neural Chip Design [1/4: Overview]
          </h2>
        </div>
        <div class="m-article-card__timestamp">
          <span>a month ago</span>
          <span>&bull;</span>
          <span>5 min read</span>
        </div>
      </a>
    </div>
  </article>
    </div>
                    </div>
                  </div>
                  <div data-glide-el="controls" class="glide__arrows js-controls">
                    <button data-glide-dir="<" class="m-icon-button filled in-recommended-articles glide-prev" aria-label="Previous">
                      <span class="icon-arrow-left" aria-hidden="true"></span>
                    </button>
                    <button data-glide-dir=">" class="m-icon-button filled in-recommended-articles glide-next" aria-label="Next">
                      <span class="icon-arrow-right" aria-hidden="true"></span>
                    </button>
                  </div>
                </div>
              </div>
            </div>
          </section>
    </div>
  </article>
</main>



    
<div class="m-search js-search" role="dialog" aria-modal="true" aria-label="Search">
  <button class="m-icon-button outlined as-close-search js-close-search" aria-label="Close search">
    <span class="icon-close" aria-hidden="true"></span>
  </button>
  <div class="m-search__content">
    <form class="m-search__form">
      <div class="pos-relative">
        <span class="icon-search m-search-icon" aria-hidden="true"></span>
        <label for="search-input" class="sr-only">
          Type to search
        </label>
        <input id="search-input" type="text" class="m-input in-search js-input-search" placeholder="Type to search">
      </div>
    </form>
    <div class="js-search-results hide"></div>
    <p class="m-not-found align-center hide js-no-results">
      No results for your search, please try with something else.
    </p>
  </div>
</div>

    
<footer class="m-footer">
  <div class="m-footer__content">
    <nav class="m-footer-social">
        <a href="https://www.facebook.com/abarajithan11" target="_blank" rel="noopener" aria-label="Facebook">
          <span class="icon-facebook" aria-hidden="true"></span>
        </a>
      <a href="https://www.linkedin.com/in/abarajithan11" target="_blank" rel="noopener" aria-label="LinkedIn">
        <span class="icon-linkedin" aria-hidden="true"></span>
      </a>
      <a href="https://github.com/abarajithan11" target="_blank" rel="noopener" aria-label="Github">
        <span class="icon-github" aria-hidden="true"></span>
      </a>
      <a href="https://aba-blog.xyz/rss" aria-label="RSS">
        <span class="icon-rss" aria-hidden="true"></span>
      </a>
    </nav>
    <p class="m-footer-copyright">
      <span>Aba&#x27;s Blog &copy; 2022</span>
      <span>&nbsp; &bull; &nbsp;</span>
      <span>Published with <a href="https://ghost.org" target="_blank" rel="noopener">Ghost</a></span>
    </p>
    <p class="m-footer-copyright jslicense">
      <a href="../assets/html/javascript.html%3Fv=b8c8d4f5ca.html" rel="jslicense">JavaScript license information</a>
    </p>
  </div>
</footer>

    <script crossorigin="anonymous" src="https://polyfill.io/v3/polyfill.min.js?features=IntersectionObserver%2CPromise%2CArray.prototype.includes%2CString.prototype.endsWith%2CString.prototype.startsWith%2CObject.assign%2CNodeList.prototype.forEach"></script>
    <script defer src="../assets/js/manifest.js%3Fv=b8c8d4f5ca"></script>
    <script defer src="../assets/js/vendor/content-api.min.js%3Fv=b8c8d4f5ca"></script>
    <script defer src="../assets/js/vendor.js%3Fv=b8c8d4f5ca"></script>
    <script defer src="../assets/js/app.js%3Fv=b8c8d4f5ca"></script>

      <script defer src="../assets/js/post.js%3Fv=b8c8d4f5ca"></script>


    <div id="fb-root"></div>
<script async defer crossorigin="anonymous" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&version=v12.0" nonce="C5ma3g6v"></script>

<script>
    window.addEventListener('DOMContentLoaded', (event) => {
        document.querySelectorAll('pre[class*=language-]').forEach(function (node) {
            node.classList.add('line-numbers');
        });
        Prism.highlightAll();
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/line-numbers/prism-line-numbers.min.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/toolbar/prism-toolbar.min.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/copy-to-clipboard/prism-copy-to-clipboard.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/components/prism-python.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/components/prism-c.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/components/prism-cpp.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/components/prism-matlab.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/components/prism-tcl.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/components/prism-verilog.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/components/prism-latex.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/components/prism-verilog.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/components/prism-yaml.min.js"></script>
  </body>
</html>
